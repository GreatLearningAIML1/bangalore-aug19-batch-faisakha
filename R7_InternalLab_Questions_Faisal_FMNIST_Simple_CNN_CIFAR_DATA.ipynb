{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "6d2bd962-a3bd-4658-d1a1-69f7130992c7"
      },
      "source": [
        "print('Training independent variables')\n",
        "print (x_train.shape)\n",
        "print('Training target data')\n",
        "print(y_train.shape)\n",
        "print('Test independent variables')\n",
        "print (x_test.shape)\n",
        "print('Test target data')\n",
        "print(y_test.shape)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training independent variables\n",
            "(60000, 28, 28)\n",
            "Training target data\n",
            "(60000,)\n",
            "Test independent variables\n",
            "(10000, 28, 28)\n",
            "Test target data\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX59l1MiRRUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "420ef3a3-b37c-47a7-e4d4-caac21b3299d"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 ... 3 0 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "926ab1a8-6e93-4695-f84f-d0c9e5522a7a"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(110) \n",
        "np.unique(y_train)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD56ZYNBexk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c1dd168b-4fda-4d0b-dbb4-fc97f5175247"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[1,:,:],cmap='gray')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4ce8bc7710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEzP1znGmrD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d8628790-0da2-47e3-cf03-0403179a9909"
      },
      "source": [
        "plt.imshow(x_test[0,:,:],cmap='gray')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4ce8bdf7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkARhB5Ig7EAShB1IgrADSfwvFVP+6jE8J4kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "eacd299a-2dd4-411a-ca35-831b258c4bac"
      },
      "source": [
        "print ('Shape of x_train is 60000*28*28 \\nSo there are 60000 samples of pixels 28*28, hence dimension is 28*28')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train is 60000*28*28 \n",
            "So there are 60000 samples of pixels 28*28, hence dimension is 28*28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EJv6z96na-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "39739d38-7bd6-4d66-a844-e9f38827d34a"
      },
      "source": [
        "import pandas as pd\n",
        "L=pd.DataFrame(y_train)\n",
        "L[0].value_counts()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9    6000\n",
              "8    6000\n",
              "7    6000\n",
              "6    6000\n",
              "5    6000\n",
              "4    6000\n",
              "3    6000\n",
              "2    6000\n",
              "1    6000\n",
              "0    6000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f0d7cb1-1812-451d-cfd0-cec792ab3edb"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y_train=np_utils.to_categorical(y_train,10)\n",
        "y_test=np_utils.to_categorical(y_test,10)\n",
        "y_train[2]\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train/= 255\n",
        "x_test/= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dff5da5-b677-4014-ccb5-7e7326488598"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],28, 28,1)\n",
        "x_train.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "530c9485-8b72-47d1-a5a8-acc9191fffd0"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "model.fit(x_train,y_train,batch_size=32,nb_epoch=10,verbose=1,callbacks=[es])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.3702 - acc: 0.8669\n",
            "Epoch 2/10\n",
            "  960/60000 [..............................] - ETA: 10s - loss: 0.2463 - acc: 0.9156"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.2251 - acc: 0.9166\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1624 - acc: 0.9390\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1120 - acc: 0.9583\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0739 - acc: 0.9730\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0462 - acc: 0.9833\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0363 - acc: 0.9869\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0262 - acc: 0.9904\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0223 - acc: 0.9919\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0190 - acc: 0.9934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "929eef06-d6cd-49da-afc2-443ec7c8a1af"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
        "model.fit(x_train,y_train,batch_size=32,nb_epoch=10,verbose=1,callbacks=[es])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.3928 - acc: 0.8604\n",
            "Epoch 2/10\n",
            " 1120/60000 [..............................] - ETA: 8s - loss: 0.2667 - acc: 0.9036"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.2554 - acc: 0.9052\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.2086 - acc: 0.9225\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.1741 - acc: 0.9338\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.1472 - acc: 0.9448\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.1258 - acc: 0.9532\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.1041 - acc: 0.9606\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0906 - acc: 0.9656\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0792 - acc: 0.9704\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 147us/step - loss: 0.0682 - acc: 0.9743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=True)  # randomly flip images\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "c0fdaaea-65d5-4b02-c4ed-844b5bccf30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCJRI/4Pir/W4csMUMcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "5ad2ccdc-8f57-46aa-e775-8f7beab6ab17"
      },
      "source": [
        "model.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test), callbacks=[es])"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  10/1875 [..............................] - ETA: 24s - loss: 5.2981 - acc: 0.1688"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 21s 11ms/step - loss: 1.6416 - acc: 0.3932 - val_loss: 1.1048 - val_acc: 0.6016\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 1.1677 - acc: 0.5755 - val_loss: 0.9234 - val_acc: 0.6709\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 1.0429 - acc: 0.6228 - val_loss: 0.9404 - val_acc: 0.6742\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.9685 - acc: 0.6483 - val_loss: 0.9371 - val_acc: 0.6793\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.9254 - acc: 0.6634 - val_loss: 0.8892 - val_acc: 0.6924\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.8873 - acc: 0.6789 - val_loss: 0.8175 - val_acc: 0.7203\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.8625 - acc: 0.6859 - val_loss: 0.7949 - val_acc: 0.7328\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.8385 - acc: 0.6958 - val_loss: 0.7905 - val_acc: 0.7290\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.8260 - acc: 0.7013 - val_loss: 0.8216 - val_acc: 0.7216\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.8066 - acc: 0.7065 - val_loss: 0.7090 - val_acc: 0.7529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4cc58455f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "537fa3cd-2c73-4e8b-84ff-4024b2d1d685"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.7089703319072723, 0.7529]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=True,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "555bd5ff-fa0a-4cf4-db3e-9b8fd6b6dd43"
      },
      "source": [
        "print('Training independent variables')\n",
        "print (x_train.shape)\n",
        "print('Training target data')\n",
        "print(y_train.shape)\n",
        "print('Test independent variables')\n",
        "print (x_test.shape)\n",
        "print('Test target data')\n",
        "print(y_test.shape)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training independent variables\n",
            "(50000, 32, 32, 3)\n",
            "Training target data\n",
            "(50000, 1)\n",
            "Test independent variables\n",
            "(10000, 32, 32, 3)\n",
            "Test target data\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "779ed71a-907e-4153-8821-73b5a5f7d3e7"
      },
      "source": [
        "x_train.dtype"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLaxxiC74Bic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "23b07acf-263b-4a49-86c6-bcc8fff8b804"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[1,:,:],cmap='gray')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4cc40afb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWmKmUgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "a57cbec6-aadf-45bc-bc22-bc9d9bdb650c"
      },
      "source": [
        "import keras\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "#save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model'\n",
        "\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAABL0lEQVR4nO3aMQ6EMAwAwcuJ/3/ZPAAkRLMUmWmT\nwnKxSpE1Mz8AGv+vBwDYiegChEQXICS6ACHRBQiJLkDoeDjf5T/ZenHXTu7Zy5WdXG2/Ey9dgJDo\nAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoRE\nFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAk\nugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh\n0QUIiS5ASHQBQqILEBJdgNCama9nANiGly5ASHQBQqILEBJdgJDoAoREFyB0AqsFC4t0MYIKAAAA\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZB_HdWN56mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "#save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKWpus_X6IU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cad95954-47d2-47a5-de57-84fda5558e80"
      },
      "source": [
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9WMtt6e6PWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3aed6487-b8f2-4e86-a73b-a6ccdaa2a79a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Convolution2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Convolution2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.9035 - acc: 0.3034 - val_loss: 1.5816 - val_acc: 0.4355\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5966 - acc: 0.4171 - val_loss: 1.4083 - val_acc: 0.4904\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.4734 - acc: 0.4682 - val_loss: 1.3078 - val_acc: 0.5263\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.3892 - acc: 0.4985 - val_loss: 1.2552 - val_acc: 0.5532\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.3197 - acc: 0.5270 - val_loss: 1.2226 - val_acc: 0.5696\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2673 - acc: 0.5487 - val_loss: 1.1745 - val_acc: 0.5873\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.2118 - acc: 0.5655 - val_loss: 1.0895 - val_acc: 0.6206\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1745 - acc: 0.5837 - val_loss: 1.0722 - val_acc: 0.6283\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.1413 - acc: 0.5979 - val_loss: 1.0086 - val_acc: 0.6437\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.1078 - acc: 0.6097 - val_loss: 1.0012 - val_acc: 0.6479\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0826 - acc: 0.6197 - val_loss: 0.9955 - val_acc: 0.6522\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0577 - acc: 0.6276 - val_loss: 0.9793 - val_acc: 0.6613\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0310 - acc: 0.6378 - val_loss: 0.9246 - val_acc: 0.6754\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.0174 - acc: 0.6415 - val_loss: 0.8962 - val_acc: 0.6888\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9998 - acc: 0.6489 - val_loss: 0.9348 - val_acc: 0.6786\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9799 - acc: 0.6566 - val_loss: 0.8469 - val_acc: 0.7063\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9619 - acc: 0.6614 - val_loss: 0.8536 - val_acc: 0.6995\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9490 - acc: 0.6686 - val_loss: 0.8316 - val_acc: 0.7146\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9391 - acc: 0.6729 - val_loss: 0.8229 - val_acc: 0.7161\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9248 - acc: 0.6774 - val_loss: 0.7985 - val_acc: 0.7236\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9200 - acc: 0.6777 - val_loss: 0.8128 - val_acc: 0.7161\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.9110 - acc: 0.6840 - val_loss: 0.7730 - val_acc: 0.7339\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.8997 - acc: 0.6866 - val_loss: 0.8070 - val_acc: 0.7267\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8856 - acc: 0.6926 - val_loss: 0.7749 - val_acc: 0.7321\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8828 - acc: 0.6949 - val_loss: 0.7807 - val_acc: 0.7260\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8721 - acc: 0.6967 - val_loss: 0.7819 - val_acc: 0.7313\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8648 - acc: 0.6994 - val_loss: 0.7758 - val_acc: 0.7318\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8579 - acc: 0.7015 - val_loss: 0.7498 - val_acc: 0.7445\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8563 - acc: 0.7035 - val_loss: 0.7752 - val_acc: 0.7310\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8506 - acc: 0.7035 - val_loss: 0.8417 - val_acc: 0.7178\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8460 - acc: 0.7070 - val_loss: 0.7152 - val_acc: 0.7588\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8409 - acc: 0.7087 - val_loss: 0.7952 - val_acc: 0.7281\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8390 - acc: 0.7087 - val_loss: 0.7074 - val_acc: 0.7582\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8281 - acc: 0.7137 - val_loss: 0.7155 - val_acc: 0.7567\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8270 - acc: 0.7156 - val_loss: 0.7084 - val_acc: 0.7642\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8247 - acc: 0.7159 - val_loss: 0.7322 - val_acc: 0.7552\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8217 - acc: 0.7180 - val_loss: 0.7666 - val_acc: 0.7362\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8132 - acc: 0.7216 - val_loss: 0.7098 - val_acc: 0.7580\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8157 - acc: 0.7183 - val_loss: 0.7250 - val_acc: 0.7574\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8175 - acc: 0.7197 - val_loss: 0.7765 - val_acc: 0.7420\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8123 - acc: 0.7235 - val_loss: 0.6949 - val_acc: 0.7654\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8107 - acc: 0.7217 - val_loss: 0.7552 - val_acc: 0.7477\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8091 - acc: 0.7251 - val_loss: 0.6899 - val_acc: 0.7676\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8053 - acc: 0.7264 - val_loss: 0.7116 - val_acc: 0.7544\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8045 - acc: 0.7249 - val_loss: 0.7330 - val_acc: 0.7529\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8068 - acc: 0.7243 - val_loss: 0.6921 - val_acc: 0.7669\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7992 - acc: 0.7257 - val_loss: 0.7199 - val_acc: 0.7658\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8012 - acc: 0.7291 - val_loss: 0.7402 - val_acc: 0.7482\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8030 - acc: 0.7270 - val_loss: 0.7039 - val_acc: 0.7668\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7982 - acc: 0.7293 - val_loss: 0.8062 - val_acc: 0.7316\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 0.7972 - acc: 0.7288 - val_loss: 0.7228 - val_acc: 0.7589\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8000 - acc: 0.7294 - val_loss: 0.7360 - val_acc: 0.7580\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7974 - acc: 0.7290 - val_loss: 0.7270 - val_acc: 0.7569\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7952 - acc: 0.7317 - val_loss: 0.6968 - val_acc: 0.7739\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7908 - acc: 0.7335 - val_loss: 0.7702 - val_acc: 0.7515\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7947 - acc: 0.7291 - val_loss: 0.7510 - val_acc: 0.7491\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7922 - acc: 0.7312 - val_loss: 0.7579 - val_acc: 0.7456\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7909 - acc: 0.7320 - val_loss: 0.7215 - val_acc: 0.7575\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7926 - acc: 0.7325 - val_loss: 0.6980 - val_acc: 0.7658\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7939 - acc: 0.7319 - val_loss: 0.7416 - val_acc: 0.7503\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7913 - acc: 0.7342 - val_loss: 0.7517 - val_acc: 0.7575\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7919 - acc: 0.7320 - val_loss: 0.6888 - val_acc: 0.7717\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7946 - acc: 0.7329 - val_loss: 0.7460 - val_acc: 0.7576\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7859 - acc: 0.7353 - val_loss: 0.7030 - val_acc: 0.7653\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7903 - acc: 0.7344 - val_loss: 0.7065 - val_acc: 0.7643\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7948 - acc: 0.7335 - val_loss: 0.7165 - val_acc: 0.7691\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7901 - acc: 0.7345 - val_loss: 0.7310 - val_acc: 0.7577\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7883 - acc: 0.7355 - val_loss: 0.7198 - val_acc: 0.7656\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7870 - acc: 0.7361 - val_loss: 0.7653 - val_acc: 0.7407\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7894 - acc: 0.7359 - val_loss: 0.7317 - val_acc: 0.7617\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7876 - acc: 0.7372 - val_loss: 0.7585 - val_acc: 0.7487\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7836 - acc: 0.7369 - val_loss: 0.7088 - val_acc: 0.7616\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7915 - acc: 0.7343 - val_loss: 0.7121 - val_acc: 0.7677\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7876 - acc: 0.7350 - val_loss: 0.7368 - val_acc: 0.7570\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7889 - acc: 0.7352 - val_loss: 0.7025 - val_acc: 0.7652\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7909 - acc: 0.7361 - val_loss: 0.7563 - val_acc: 0.7631\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7913 - acc: 0.7356 - val_loss: 0.7904 - val_acc: 0.7356\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7894 - acc: 0.7348 - val_loss: 0.8287 - val_acc: 0.7420\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7859 - acc: 0.7385 - val_loss: 0.6838 - val_acc: 0.7720\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7899 - acc: 0.7348 - val_loss: 0.7507 - val_acc: 0.7552\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7932 - acc: 0.7352 - val_loss: 0.7155 - val_acc: 0.7604\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7872 - acc: 0.7363 - val_loss: 0.7097 - val_acc: 0.7709\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7938 - acc: 0.7360 - val_loss: 0.7961 - val_acc: 0.7387\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7926 - acc: 0.7368 - val_loss: 0.7396 - val_acc: 0.7676\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7900 - acc: 0.7363 - val_loss: 0.7858 - val_acc: 0.7426\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7925 - acc: 0.7346 - val_loss: 0.6967 - val_acc: 0.7691\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8010 - acc: 0.7353 - val_loss: 0.8466 - val_acc: 0.7162\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7976 - acc: 0.7348 - val_loss: 0.7649 - val_acc: 0.7474\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7953 - acc: 0.7359 - val_loss: 0.7888 - val_acc: 0.7452\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7939 - acc: 0.7367 - val_loss: 0.7607 - val_acc: 0.7472\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7921 - acc: 0.7362 - val_loss: 0.7146 - val_acc: 0.7667\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7957 - acc: 0.7360 - val_loss: 0.7902 - val_acc: 0.7337\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7959 - acc: 0.7370 - val_loss: 0.8519 - val_acc: 0.7244\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.8035 - acc: 0.7350 - val_loss: 0.8185 - val_acc: 0.7325\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 0.7946 - acc: 0.7367 - val_loss: 0.7399 - val_acc: 0.7579\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8032 - acc: 0.7346 - val_loss: 0.7123 - val_acc: 0.7618\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8007 - acc: 0.7335 - val_loss: 0.7358 - val_acc: 0.7605\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8094 - acc: 0.7301 - val_loss: 0.6960 - val_acc: 0.7735\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8010 - acc: 0.7343 - val_loss: 0.7644 - val_acc: 0.7464\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8032 - acc: 0.7346 - val_loss: 0.8010 - val_acc: 0.7422\n",
            "10000/10000 [==============================] - 1s 91us/step\n",
            "Test loss: 0.8009633919715882\n",
            "Test accuracy: 0.7422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "18106987-7cfe-4df1-e4f9-767ae0d27f80"
      },
      "source": [
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-b8006bb5ea44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m model.add(Conv2D(32, (3, 3), padding='same',\n\u001b[0m\u001b[1;32m     22\u001b[0m                  input_shape=x_train.shape[1:]))\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "7e380479-5526-45cc-90f4-335630e2ba67"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}